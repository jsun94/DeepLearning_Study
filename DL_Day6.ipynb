{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution(progresses, speeds):\n",
    "    for i in range(len(progresses)-1):\n",
    "        while (progresses[i] <=100):\n",
    "            progresses[i] = progresses[i] + speeds[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 필터를 증가 시켰다 -> 복잡도 증가\n",
    "- dropout -> 모델이 복잡할 때 너무 세세한 정보를 걸러내기 위해 사용하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "idx2char = ['h','i','e','l','o']\n",
    "\n",
    "# hihell을 입력하여 ihello를 도출한다. -> 자기 자신의 다음 알파벳을 도출\n",
    "\n",
    "x_data = [[0,1,0,2,3,3]]  # hihell\n",
    "x_one_hot = [[[1,0,0,0,0],  # h 0\n",
    "             [0,1,0,0,0],   # i 1\n",
    "             [1,0,0,0,0],   # h 0\n",
    "             [0,0,1,0,0],   # e 2\n",
    "             [0,0,0,1,0],   # l 3\n",
    "             [0,0,0,1,0]]]  # l 3\n",
    "\n",
    "y_data = [[1,0,2,3,3,4]] #ihello\n",
    "\n",
    "num_classes = 5\n",
    "input_dim = 5\n",
    "hidden_size = 5\n",
    "batch_size = 1\n",
    "sequence_length = 6\n",
    "learning_rate = 0.1\n",
    "\n",
    "#sequence_length = 글자의 개수(6)를 의미하고, input_dim = 백터 인덱스 값 (5)\n",
    "X = tf.placeholder(tf.float32, [None, sequence_length, input_dim]) # X one-hot\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length]) # Y label\n",
    "\n",
    "\n",
    "#num_units -> 행렬곱의 가능을 위해 input dimension과 같다고 생각하면 됌\n",
    "cell = tf.contrib.rnn.BasicRNNCell(num_units = hidden_size)\n",
    "\n",
    "#처음 노드의 가중치를 위한 값을 0으로 하겠다\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "#dynamic_rnn은 셀의 모양을 다양하게 해주는 것 \n",
    "#엄밀하게 X의 데이터에 대해서 자동으로 시퀀스를 결정해주는 것\n",
    "outputs, _states = tf.nn.dynamic_rnn(\n",
    "    cell, X, initial_state = initial_state, dtype = tf.float32)\n",
    "\n",
    "X_for_fc = tf.reshape(outputs, [-1, hidden_size])\n",
    "\n",
    "outputs = tf.contrib.layers.fully_connected(\n",
    "    inputs = X_for_fc, num_outputs = num_classes, activation_fn = None)\n",
    "\n",
    "\n",
    "#batch_size = 'hihello' 하나, sequence_length = 'hihell' / 'ihello' -> 6\n",
    "#num_classes = 글자 하나당 벡터 5개 [0,1,0,0,0]\n",
    "outputs = tf.reshape(outputs, [batch_size, sequence_length, num_classes])\n",
    "\n",
    "weights = tf.ones([batch_size,sequence_length])\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "    logits = outputs, targets = Y, weights = weights)\n",
    "loss = tf.reduce_mean(sequence_loss)\n",
    "train = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "\n",
    "prediction = tf.argmax(outputs, axis = 2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(50):\n",
    "        l, _ = sess.run([loss, train], feed_dict={X: x_one_hot, Y: y_data})\n",
    "        result = sess.run(prediction, feed_dict={X: x_one_hot})\n",
    "        print(i, \"loss:\", l, \"prediction: \", result, \"true Y: \", y_data)\n",
    "\n",
    "        # print char using dic\n",
    "        #squeeze -> 차원에서 1인 것을 없애줌\n",
    "        result_str = [idx2char[c] for c in np.squeeze(result)]\n",
    "        print(\"\\tPrediction str: \", ''.join(result_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "y_data = tf.constant([1,1,1])\n",
    "\n",
    "prediction1 = tf.constant([[[0.3,0.7],[0.3,0.7],[0.3,0.7]]], dtype = tf.float32)\n",
    "prediction2 = tf.constant([[[0.1,0.9],[0.1,0.9],[0.1,0.9]]], dtype = tf.float32)\n",
    "\n",
    "prediction3 = tf.constant([[[1,0],[1,0],[1,0]]], dtype = tf.float32)\n",
    "prediction4 = tf.constant([[[0,1],[1,0],[0,1]]], dtype = tf.float32)\n",
    "\n",
    "weights = tf.constant([[1,1,1]], dtype = tf.float32)\n",
    "\n",
    "sequence_loss1 = tf.contrib.seq2seq.sequence_loss(prediction1, y_data, weights)\n",
    "sequence_loss2 = tf.contrib.seq2seq.sequence_loss(prediction2, y_data, weights)\n",
    "sequence_loss3 = tf.contrib.seq2seq.sequence_loss(prediction3, y_data, weights)\n",
    "sequence_loss4 = tf.contrib.seq2seq.sequence_loss(prediction4, y_data, weights)\n",
    "\n",
    "\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('Loss1 : ', sequence_loss1.eval(),\n",
    "     'Loss2 : ', sequence_loss2.eval(),\n",
    "     'Loss3 : ', sequence_loss3.eval(),\n",
    "     'Loss4 : ', sequence_loss4.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)\n",
    "tf.compat.c1.reset_default_graph() #그래프 리셋 / 없을 시 두번 실행하면 에러남\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "idx2char = ['_','I','l','o','v','e','y','u','!']\n",
    "\n",
    "# hihell을 입력하여 ihello를 도출한다. -> 자기 자신의 다음 알파벳을 도출\n",
    "\n",
    "x_data = [[0,1,0,2,3,4,5,0,6,3,7]]  # _I_love_you\n",
    "x_one_hot = [[[1,0,0,0,0,0,0,0,0],  # _ 0\n",
    "             [0,1,0,0,0,0,0,0,0],   # I 1\n",
    "             [1,0,0,0,0,0,0,0,0],   # _ 0\n",
    "             [0,0,1,0,0,0,0,0,0],   # l 2\n",
    "             [0,0,0,1,0,0,0,0,0],   # o 3\n",
    "             [0,0,0,0,1,0,0,0,0],   # v 4\n",
    "             [0,0,0,0,0,1,0,0,0],   # e 5\n",
    "             [1,0,0,0,0,0,0,0,0],   # _ 0\n",
    "             [0,0,0,0,0,0,1,0,0],   # y 6\n",
    "             [0,0,0,1,0,0,0,0,0],   # o 3\n",
    "             [0,0,0,0,0,0,0,1,0]]]  # u 7\n",
    "\n",
    "y_data = [[1,0,2,3,4,5,0,6,3,7,8]] #ihello\n",
    "\n",
    "num_classes = 9\n",
    "input_dim = 9\n",
    "hidden_size = 9\n",
    "batch_size = 1\n",
    "sequence_length = 11\n",
    "learning_rate = 0.1\n",
    "\n",
    "#sequence_length = 글자의 개수(6)를 의미하고, input_dim = 백터 인덱스 값 (5)\n",
    "X = tf.placeholder(tf.float32, [None, sequence_length, input_dim]) # X one-hot\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length]) # Y label\n",
    "\n",
    "\n",
    "#num_units -> 행렬곱의 가능을 위해 input dimension과 같다고 생각하면 됌\n",
    "cell = tf.contrib.rnn.BasicRNNCell(num_units = hidden_size)\n",
    "\n",
    "#처음 노드의 가중치를 위한 값을 0으로 하겠다\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "#dynamic_rnn은 셀의 모양을 다양하게 해주는 것 \n",
    "#엄밀하게 X의 데이터에 대해서 자동으로 시퀀스를 결정해주는 것\n",
    "outputs, _states = tf.nn.dynamic_rnn(\n",
    "    cell, X, initial_state = initial_state, dtype = tf.float32)\n",
    "\n",
    "X_for_fc = tf.reshape(outputs, [-1, hidden_size])\n",
    "\n",
    "outputs = tf.contrib.layers.fully_connected(\n",
    "    inputs = X_for_fc, num_outputs = num_classes, activation_fn = None)\n",
    "#activation_fn -> 출력하려는 값이 숫자이므로 None이나 굳이 쓰면 relu\n",
    "\n",
    "\n",
    "#batch_size = 'hihello' 하나, sequence_length = 'hihell' / 'ihello' -> 6\n",
    "#num_classes = 글자 하나당 벡터 5개 [0,1,0,0,0]\n",
    "outputs = tf.reshape(outputs, [batch_size, sequence_length, num_classes])\n",
    "\n",
    "weights = tf.ones([batch_size,sequence_length])\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "    logits = outputs, targets = Y, weights = weights)\n",
    "loss = tf.reduce_mean(sequence_loss)\n",
    "train = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "\n",
    "prediction = tf.argmax(outputs, axis = 2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(50):\n",
    "        l, _ = sess.run([loss, train], feed_dict={X: x_one_hot, Y: y_data})\n",
    "        result = sess.run(prediction, feed_dict={X: x_one_hot})\n",
    "        print(i, \"loss:\", l, \"prediction: \", result, \"true Y: \", y_data)\n",
    "\n",
    "        # print char using dic\n",
    "        #squeeze -> 차원에서 1인 것을 없애줌\n",
    "        result_str = [idx2char[c] for c in np.squeeze(result)]\n",
    "        print(\"\\tPrediction str: \", ''.join(result_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
