{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tensorflow를 활용한 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지도 / 비지도 학습\n",
    "\n",
    "(White)XAI / Blackbox AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XAI - 도출된 결과를 논리적으로 설명 가능한 것 - 결정 트리\n",
    "\n",
    "Blackbox AI(Algorithm) - SVM, ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 연산 그래프\n",
    "- 노드와 노드의 연관성을 엣지로 표현한 것을 그래프라고 한다.\n",
    "- 자기 자신으로 돌아올 수 있는 엣지를 net이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 회귀 이해\n",
    "- 하나의 종속 변수(예측하고자 하는 값)와 독립 변수(예측자) 차이의 관계를 명시하는 것\n",
    "- 예 :\n",
    "    - 경제, 사회학, 심리학, 물리학 생태학 같은 분야에서 측정된 특성으로, 모집단과 개별이 어떻게 다른지 평가\n",
    "    - 임상 약품 실험, 엔지니어링 안전 검사, 시장 연구 같은 사건과 결과 같이 인과 관계를 수량화\n",
    "    \n",
    "- y-y'을 제곱하는 이유는 미분을 하여 기울기가 0인 값을 찾기 위하여"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다중 선형 회귀\n",
    "- 장점:\n",
    "    - 수치 데이터를 모델화하기 위한 가장 일반적인 접근법\n",
    "    - 거의 모든 데이터 모델화 가능\n",
    "    - 속성과 결과 간 관계의 견고성과 크기를 추정할 수 있다.\n",
    "- 단점:\n",
    "    - 데이터에 대한 강한 가정을 만든다.\n",
    "    - 사전에 모델의 형태가 사용자로부터 명시돼어야만 한다.\n",
    "    - 결측치와 잘 작동하지 않는다.\n",
    "    - 수치 속성만 작동하고 범주형 데이터는 부가 처리가 필요\n",
    "    - 모델을 이해하려면 통계적 일부가 필요\n",
    "    - bias가 되어 있어도 알 방법이 없다.\n",
    "------------------------------------------------------------------\n",
    "> ad-bc = 0이면 벡터의 미분이 불가하여 기울기를 구할 수 없으므로 인공지능에서는 오차를 단계적으로 줄여가는 방법인 그레디언트 디센트 방법을 사용한다.(기울기 감소) <기울기가 양수이면 왼쪽으로, 음수이면 오른쪽으로 줄인다.>\n",
    "\n",
    "> 기울기가 크면 크게 줄이고, 작으면 작게 줄이는 모멘텀 ㅇㅅㅇ\n",
    "\n",
    "> 기울기를 감소시키기 위한 보폭 : learning rate (lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\edu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() #버젼 2를 1처럼 사용하기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(5)\n",
    "b = tf.constant(2)\n",
    "c = tf.constant(3)\n",
    "\n",
    "d = tf.multiply(a,b)\n",
    "e = tf.add(c,b)\n",
    "f = tf.subtract(d,e)\n",
    "\n",
    "with tf.Session() as sess: #세션은 메모리를 로딩해서 실행시킬 공간\n",
    "    feches = [d,e,f]\n",
    "    outs = sess.run(feches)#여러개를 실행하려면 리스트로 \n",
    "print(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre run: \n",
      "<tf.Variable 'val:0' shape=(1, 5) dtype=float32_ref>\n",
      "\n",
      "post run : \n",
      "[[-0.5992992  -0.18848003 -1.2878184  -0.01626598  1.4618697 ]]\n"
     ]
    }
   ],
   "source": [
    "init_val = tf.random_normal((1,5),0,1)\n",
    "var = tf.Variable(init_val, name = 'val') #변수만 생성, 초기화 X\n",
    "print('pre run: \\n{}'.format(var)) #연산의 그릇만 만듦\n",
    "\n",
    "init = tf.global_variables_initializer() #세션 초기화\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    post_var = sess.run(var) #연산 실행\n",
    "print('\\npost run : \\n{}'.format(post_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs = [array([[-0.5353518 ,  1.0018202 ,  0.8844218 , -0.41426608, -1.0104144 ,\n",
      "         0.10144283,  1.6593348 , -2.0853562 ,  0.7886568 ,  0.03637885],\n",
      "       [ 0.605257  ,  0.03737352,  0.48593667,  0.2931935 , -0.84570086,\n",
      "        -1.1260196 ,  0.8681113 ,  0.8654506 , -1.5691844 ,  0.52187276],\n",
      "       [-1.0257127 , -0.708803  , -1.2674724 ,  0.36401534,  0.45786822,\n",
      "         0.48875317, -0.36387804, -0.57727957, -1.5540916 ,  0.74392194],\n",
      "       [-0.51337683, -1.029671  , -0.88030624,  0.47498968,  0.04326763,\n",
      "         0.02397016,  0.6678749 , -0.89585716, -2.6916199 , -0.56610286],\n",
      "       [ 1.5809553 ,  0.57870305, -0.71632713,  0.8773585 , -0.7423135 ,\n",
      "         0.4340933 , -1.0564862 , -0.7464267 , -1.1489038 , -0.1964793 ]],\n",
      "      dtype=float32), array([[ 0.54970956],\n",
      "       [-0.20357376],\n",
      "       [-0.5358052 ],\n",
      "       [ 0.6449339 ],\n",
      "       [-0.5027265 ],\n",
      "       [-1.3238457 ],\n",
      "       [ 0.44850013],\n",
      "       [ 1.0764254 ],\n",
      "       [ 1.063094  ],\n",
      "       [ 3.6007524 ]], dtype=float32), array([[-1.],\n",
      "       [-1.],\n",
      "       [-1.],\n",
      "       [-1.],\n",
      "       [-1.]], dtype=float32), array([[-1.396728 ],\n",
      "       [ 3.7015479],\n",
      "       [-0.1409471],\n",
      "       [-4.9126916],\n",
      "       [-1.7067573]], dtype=float32), array([[-2.396728 ],\n",
      "       [ 2.7015479],\n",
      "       [-1.1409471],\n",
      "       [-5.9126916],\n",
      "       [-2.7067573]], dtype=float32), 2.7015479]\n"
     ]
    }
   ],
   "source": [
    "x_data = np.random.randn(5,10)\n",
    "w_data = np.random.randn(10,1)\n",
    "\n",
    "#그래프란 실행할 수 있게 하는 스케치 공간\\\n",
    "with tf.Graph().as_default(): \n",
    "    x = tf.placeholder(tf.float32,shape = (5,10))#값을 가지고 있지 않은 빈 그릇\n",
    "    w = tf.placeholder(tf.float32,shape = (10,1))\n",
    "    b = tf.fill((5,1),-1.)\n",
    "    xw = tf.matmul(x,w)\n",
    "    xwb = xw + b\n",
    "    s = tf.reduce_max(xwb) # 가장 큰 값을 뽑아내시오\n",
    "    \n",
    "    # 세션은 실제로 동작하기 위한 (그래프가 더 큰 개념)\n",
    "    with tf.Session() as sess:\n",
    "        fetches = [x,w,b,xw,xwb,s]\n",
    "        \n",
    "        #x,w 빈 자리를 채워줌(딕셔너리 형태로)\n",
    "        outs = sess.run(fetches, feed_dict={x:x_data, w:w_data})\n",
    "        #outs = sess.run(s, feed_dict={x:x_data, w:w_data})\n",
    "print('outs = {}'.format(outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs = [array([[ 0.1017848 ,  0.41908798,  0.8575054 ,  2.1658409 ,  0.3116683 ,\n",
      "         0.70570457, -0.04719292,  0.54822993,  0.31546625, -0.75760335],\n",
      "       [ 0.31519133,  1.0570216 ,  0.43964458,  1.0613383 , -0.17832036,\n",
      "         0.71641564, -0.40029946, -0.76527613,  0.1700732 , -0.7531355 ],\n",
      "       [ 1.4524299 , -1.3660661 ,  0.95099413, -0.37483054, -1.2617995 ,\n",
      "         1.2734225 , -0.16968772, -0.91048855, -0.12877487, -0.60916024],\n",
      "       [ 0.7975576 ,  0.15874933, -1.0452194 , -1.5782081 , -0.541697  ,\n",
      "         0.8136276 , -0.5152318 ,  0.9017463 ,  0.5272401 , -0.34889716],\n",
      "       [ 1.2582545 ,  0.08801638, -0.0863977 ,  1.2895712 ,  1.649789  ,\n",
      "         0.07914744, -0.00268594,  1.2281774 ,  1.9666134 , -1.7550911 ]],\n",
      "      dtype=float32), array([[-0.8476897 ],\n",
      "       [-0.25268966],\n",
      "       [-0.71228737],\n",
      "       [ 0.28915915],\n",
      "       [ 1.3956136 ],\n",
      "       [ 2.1824424 ],\n",
      "       [ 0.07182759],\n",
      "       [ 0.92023313],\n",
      "       [ 0.00692226],\n",
      "       [ 0.612677  ]], dtype=float32), array([[-1.],\n",
      "       [-1.],\n",
      "       [-1.],\n",
      "       [-1.],\n",
      "       [-1.]], dtype=float32), array([[ 1.8375566 ],\n",
      "       [-0.41910732],\n",
      "       [-1.8777589 ],\n",
      "       [ 1.1743408 ],\n",
      "       [ 1.8891097 ]], dtype=float32), array([[ 0.8375566 ],\n",
      "       [-1.4191073 ],\n",
      "       [-2.877759  ],\n",
      "       [ 0.17434084],\n",
      "       [ 0.88910973]], dtype=float32), 0.88910973]\n"
     ]
    }
   ],
   "source": [
    "#선형 회귀로 생각을 할 수 있다.\n",
    "\n",
    "x_data = np.random.randn(5,10)\n",
    "w_data = np.random.randn(10,1)\n",
    "with tf.Graph().as_default(): \n",
    "    x = tf.placeholder(tf.float32,shape = (5,10)) # 5개 데이터 10개 속성\n",
    "    w = tf.placeholder(tf.float32,shape = (10,1)) # 가중치는 속성의 갯수만큼 10개\n",
    "    b = tf.fill((5,1),-1.) # bias는 모두 같은 값 (shape은 x*w의 shape과 같다)\n",
    "    xw = tf.matmul(x,w) # 행렬곱\n",
    "    xwb = xw + b # 회귀식의 모양\n",
    "    s = tf.reduce_max(xwb) \n",
    "    with tf.Session() as sess:\n",
    "        fetches = [x,w,b,xw,xwb,s]\n",
    "        outs = sess.run(fetches, feed_dict={x:x_data, w:w_data})\n",
    "\n",
    "print('outs = {}'.format(outs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8074949 [1.4884768] [-1.7822]\n",
      "50 0.315743 [1.6519276] [-1.4838642]\n",
      "100 0.2482004 [1.578623] [-1.3153512]\n",
      "150 0.19510806 [1.5130193] [-1.1662132]\n",
      "200 0.15337269 [1.4548519] [-1.0339854]\n",
      "250 0.12056491 [1.4032797] [-0.91674984]\n",
      "300 0.094775 [1.3575549] [-0.8128066]\n",
      "350 0.074501775 [1.3170146] [-0.7206488]\n",
      "400 0.058565225 [1.2810708] [-0.6389401]\n",
      "450 0.04603753 [1.2492023] [-0.5664953]\n",
      "500 0.0361897 [1.2209473] [-0.5022648]\n",
      "550 0.028448397 [1.1958957] [-0.44531694]\n",
      "600 0.022363031 [1.1736846] [-0.3948259]\n",
      "650 0.017579388 [1.1539919] [-0.35005972]\n",
      "700 0.013819012 [1.136532] [-0.31036925]\n",
      "750 0.010862994 [1.1210514] [-0.27517885]\n",
      "800 0.008539285 [1.1073264] [-0.24397834]\n",
      "850 0.006712649 [1.0951575] [-0.21631542]\n",
      "900 0.005276767 [1.0843683] [-0.19178917]\n",
      "950 0.0041480213 [1.0748025] [-0.1700437]\n",
      "1000 0.003260716 [1.0663211] [-0.15076374]\n",
      "1050 0.0025632193 [1.0588015] [-0.13366988]\n",
      "1100 0.0020149252 [1.0521345] [-0.11851403]\n",
      "1150 0.0015839153 [1.0462234] [-0.10507667]\n",
      "1200 0.0012451012 [1.0409826] [-0.09316287]\n",
      "1250 0.0009787609 [1.0363357] [-0.08259975]\n",
      "1300 0.0007693942 [1.032216] [-0.07323442]\n",
      "1350 0.0006048145 [1.0285631] [-0.06493082]\n",
      "1400 0.00047543677 [1.0253246] [-0.05756873]\n",
      "1450 0.0003737373 [1.0224533] [-0.05104148]\n",
      "1500 0.0002937962 [1.0199077] [-0.04525462]\n",
      "1550 0.00023094892 [1.0176502] [-0.0401234]\n",
      "1600 0.00018154543 [1.0156491] [-0.03557402]\n",
      "1650 0.00014271055 [1.0138748] [-0.03154046]\n",
      "1700 0.00011218383 [1.0123016] [-0.0279643]\n",
      "1750 8.8185385e-05 [1.0109067] [-0.02479355]\n",
      "1800 6.932092e-05 [1.00967] [-0.02198227]\n",
      "1850 5.4492146e-05 [1.0085735] [-0.01948982]\n",
      "1900 4.2835745e-05 [1.0076014] [-0.01727993]\n",
      "1950 3.367193e-05 [1.0067395] [-0.01532067]\n",
      "2000 2.6469692e-05 [1.0059754] [-0.01358353]\n"
     ]
    }
   ],
   "source": [
    "#단순 회귀 분석 / 기울기가 1이고 bias =0 인 직선을 찾는 과정\n",
    "\n",
    "x_train = [1,2,3]\n",
    "y_train = [1,2,3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight')# 변수가 하나이므로 가중치가 하나\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')# bias는 항상 하나이므로 하나\n",
    "\n",
    "#회귀식의 모형\n",
    "hypothesis = x_train * W + b\n",
    "\n",
    "#예측한 값과 예측하려는 값의 차이의 제곱의 평균\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "\n",
    "#gradient descent 방법을 통해 기울기를 찾는다, learning_rate = 0.01(보폭)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate= 0.01)\n",
    "\n",
    "#내가 원한 값(cost)를 최소화 시키도록 학습하라\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #세션에 올라가는 변수들을 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2001):\n",
    "        sess.run(train)\n",
    "        if step % 50 == 0:\n",
    "            #의도 : W = 1에, b = 0에 가까워지도록\n",
    "            print(step, sess.run(cost), sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 42.0342 [0.00566384] [-0.5415486]\n",
      "20 0.4212569 [2.0201056] [0.37582436]\n",
      "40 0.04027992 [2.2020497] [0.48561156]\n",
      "60 0.033479165 [2.2099688] [0.5174468]\n",
      "80 0.030378157 [2.201759] [0.5408544]\n",
      "100 0.027589709 [2.1924353] [0.5625019]\n",
      "120 0.025057407 [2.1834064] [0.58306926]\n",
      "140 0.022757502 [2.1747885] [0.6026641]\n",
      "160 0.020668773 [2.166574] [0.62133753]\n",
      "180 0.018771658 [2.1587458] [0.63913345]\n",
      "200 0.017048763 [2.1512852] [0.65609294]\n",
      "220 0.015483961 [2.1441755] [0.6722552]\n",
      "240 0.014062777 [2.1373997] [0.687658]\n",
      "260 0.012772028 [2.1309426] [0.70233697]\n",
      "280 0.011599767 [2.124789] [0.7163259]\n",
      "300 0.010535121 [2.118924] [0.7296573]\n",
      "320 0.009568136 [2.1133351] [0.74236256]\n",
      "340 0.008689968 [2.1080086] [0.7544705]\n",
      "360 0.007892349 [2.102933] [0.7660096]\n",
      "380 0.0071679777 [2.0980954] [0.7770063]\n",
      "400 0.006510058 [2.093485] [0.7874863]\n",
      "420 0.005912525 [2.0890918] [0.79747367]\n",
      "440 0.0053698383 [2.084905] [0.8069917]\n",
      "460 0.004876961 [2.0809138] [0.81606257]\n",
      "480 0.0044293324 [2.0771115] [0.82470727]\n",
      "500 0.00402277 [2.0734873] [0.83294547]\n",
      "520 0.0036535368 [2.0700338] [0.8407964]\n",
      "540 0.0033182197 [2.0667427] [0.8482783]\n",
      "560 0.0030136677 [2.063606] [0.85540867]\n",
      "580 0.002737048 [2.0606165] [0.862204]\n",
      "600 0.002485837 [2.0577679] [0.86867994]\n",
      "620 0.002257677 [2.0550532] [0.87485147]\n",
      "640 0.002050452 [2.0524657] [0.8807329]\n",
      "660 0.0018622681 [2.0500002] [0.88633794]\n",
      "680 0.0016913427 [2.0476503] [0.8916795]\n",
      "700 0.0015361048 [2.045411] [0.8967701]\n",
      "720 0.0013951188 [2.043277] [0.90162146]\n",
      "740 0.0012670761 [2.0412433] [0.9062446]\n",
      "760 0.0011507816 [2.039305] [0.9106508]\n",
      "780 0.0010451485 [2.0374575] [0.91485]\n",
      "800 0.0009492224 [2.035697] [0.91885185]\n",
      "820 0.0008620971 [2.0340195] [0.92266566]\n",
      "840 0.0007829722 [2.0324209] [0.9263]\n",
      "860 0.00071110297 [2.0308971] [0.9297637]\n",
      "880 0.00064583216 [2.029445] [0.9330646]\n",
      "900 0.0005865612 [2.0280612] [0.9362103]\n",
      "920 0.0005327181 [2.0267422] [0.9392084]\n",
      "940 0.00048382513 [2.0254855] [0.94206536]\n",
      "960 0.00043941705 [2.024288] [0.9447881]\n",
      "980 0.0003990914 [2.0231464] [0.94738275]\n",
      "1000 0.0003624528 [2.0220587] [0.94985574]\n",
      "1020 0.00032919063 [2.0210218] [0.9522124]\n",
      "1040 0.0002989744 [2.020034] [0.95445806]\n",
      "1060 0.00027153135 [2.0190923] [0.9565985]\n",
      "1080 0.00024660912 [2.0181952] [0.95863813]\n",
      "1100 0.00022397528 [2.01734] [0.96058196]\n",
      "1120 0.00020341773 [2.0165253] [0.96243453]\n",
      "1140 0.00018475151 [2.0157485] [0.96419984]\n",
      "1160 0.00016779301 [2.0150084] [0.9658823]\n",
      "1180 0.00015239169 [2.014303] [0.9674857]\n",
      "1200 0.000138401 [2.013631] [0.96901375]\n",
      "1220 0.0001256996 [2.0129902] [0.97047013]\n",
      "1240 0.00011416362 [2.01238] [0.97185796]\n",
      "1260 0.00010368194 [2.011798] [0.9731805]\n",
      "1280 9.4171126e-05 [2.0112436] [0.9744409]\n",
      "1300 8.552307e-05 [2.0107152] [0.97564197]\n",
      "1320 7.767531e-05 [2.0102117] [0.9767867]\n",
      "1340 7.054676e-05 [2.0097318] [0.9778776]\n",
      "1360 6.4073654e-05 [2.0092742] [0.97891724]\n",
      "1380 5.819183e-05 [2.0088384] [0.9799079]\n",
      "1400 5.2848558e-05 [2.008423] [0.98085225]\n",
      "1420 4.7999736e-05 [2.0080273] [0.9817521]\n",
      "1440 4.359383e-05 [2.0076501] [0.9826097]\n",
      "1460 3.9593884e-05 [2.0072906] [0.9834269]\n",
      "1480 3.5959503e-05 [2.006948] [0.9842058]\n",
      "1500 3.2659093e-05 [2.0066214] [0.984948]\n",
      "1520 2.9661227e-05 [2.0063102] [0.9856554]\n",
      "1540 2.6938525e-05 [2.0060136] [0.9863296]\n",
      "1560 2.446662e-05 [2.005731] [0.9869721]\n",
      "1580 2.222034e-05 [2.0054617] [0.98758435]\n",
      "1600 2.0180254e-05 [2.005205] [0.9881678]\n",
      "1620 1.8329965e-05 [2.0049608] [0.98872375]\n",
      "1640 1.6648666e-05 [2.0047276] [0.98925346]\n",
      "1660 1.5119814e-05 [2.0045052] [0.9897583]\n",
      "1680 1.3732167e-05 [2.0042937] [0.9902395]\n",
      "1700 1.2472755e-05 [2.004092] [0.99069816]\n",
      "1720 1.1326497e-05 [2.0038996] [0.9911353]\n",
      "1740 1.0287956e-05 [2.0037162] [0.99155194]\n",
      "1760 9.3439285e-06 [2.003542] [0.9919488]\n",
      "1780 8.486643e-06 [2.0033755] [0.9923271]\n",
      "1800 7.707557e-06 [2.0032167] [0.99268764]\n",
      "1820 7.00057e-06 [2.003066] [0.9930311]\n",
      "1840 6.3585335e-06 [2.0029216] [0.99335843]\n",
      "1860 5.775249e-06 [2.0027847] [0.99367046]\n",
      "1880 5.24544e-06 [2.0026538] [0.9939678]\n",
      "1900 4.764097e-06 [2.002529] [0.994251]\n",
      "1920 4.327326e-06 [2.0024104] [0.9945211]\n",
      "1940 3.93023e-06 [2.0022974] [0.9947784]\n",
      "1960 3.5704234e-06 [2.0021896] [0.99502355]\n",
      "1980 3.2429828e-06 [2.0020869] [0.99525714]\n",
      "2000 2.9456749e-06 [2.001989] [0.99547976]\n"
     ]
    }
   ],
   "source": [
    "# 단순회귀분석\n",
    "x_train = [1,2,3]\n",
    "y_train = [3,5,7]\n",
    "\n",
    "# 가중치를 벡터로\n",
    "w = tf.Variable(tf.random_normal([1]),name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]),name='bias')\n",
    "\n",
    "# shape을 None으로 주게되면 예제의 갯수에 대해서 유동적으로 동작하게 만듦 > 1차원 이기에 가능\n",
    "X = tf.placeholder(tf.float32, shape=[None]) # 3행1열 예제갯수는 3개, 속성은 1개\n",
    "Y = tf.placeholder(tf.float32, shape=[None]) # \n",
    "\n",
    "hypothesis = X * w +b # bias는 브로드캐스팅 된다 (3,1 shape의 모든 요소에 더해짐)\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "# 위 코드를 실행시키기 위해 세션을 만듦\n",
    "with tf.Session() as sess:\n",
    "    # 세션에 올라가는 변수 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2001):\n",
    "        cost_val, w_val, b_val, _ = \\\n",
    "        sess.run([cost, w, b, train], feed_dict={X:x_train, Y:y_train})\n",
    "        if step % 20 == 0:\n",
    "            print(step, cost_val, w_val, b_val) # 변경과정을 로그처럼 찍어냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  77288.11 \n",
      "Prediction:\n",
      " [-0.59569335] [2.2638364]\n",
      "1000 Cost:  nan \n",
      "Prediction:\n",
      " [-0.59569335] [nan]\n",
      "2000 Cost:  nan \n",
      "Prediction:\n",
      " [-0.59569335] [nan]\n"
     ]
    }
   ],
   "source": [
    "#선형 회귀\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "x1_data = [73.,93.,89.,98.,73.]\n",
    "x2_data = [80.,88.,91.,98.,66.]\n",
    "x3_data = [75.,93.,90.,100.,70.]\n",
    "y_data = [152.,185.,180.,196.,142.]\n",
    "\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name = 'weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name = 'weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name = 'weight3')\n",
    "\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "Y = tf.placeholder(tf.float32, shape = [5,])\n",
    "\n",
    "hypothesis = x1*w1 + x2*w2 + x3*w3 + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.0001)\n",
    "train = optimizer.minimize(cost)\n",
    "# 위 코드를 실행시키기 위해 세션을 만듦\n",
    "with tf.Session() as sess:\n",
    "    # 세션에 올라가는 변수 초기화\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2001):\n",
    "        cost_val, w_val, b_val, _ = \\\n",
    "        sess.run([cost, w, b, train], feed_dict={x1:x1_data, x2:x2_data, x3:x3_data, Y:y_data})\n",
    "        if step % 1000 == 0:\n",
    "            print(step,\"Cost: \" ,cost_val,\"\\nPrediction:\\n\", w_val, b_val) # 변경과정을 로그처럼 찍어냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
